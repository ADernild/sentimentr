% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/sentiment.R, R/sentimentr-package.R
\docType{package}
\name{sentiment}
\alias{package-sentiment}
\alias{sentiment}
\alias{sentiment-package}
\title{Polarity Score (Sentiment Analysis)}
\usage{
sentiment(text.var, polarity_dt = sentimentr::polarity_table,
  valence_shifters_dt = sentimentr::valence_shifters_table,
  amplifier.weight = 0.8, n.before = 4, n.after = 2,
  question.weight = 1, ...)
}
\arguments{
\item{text.var}{The text variable.}

\item{polarity_dt}{A \pkg{data.table} of positive/negative words and
weights with x and y as column names..}

\item{valence_shifters_dt}{A \pkg{data.table} of valence shifters that
can alter a polarized word's meaning and a numic key for negators (1),
amplifiers(2), and de-amplifiers (3) with x and y as column names.}

\item{amplifier.weight}{The weight to apply to amplifiers/deamplifiers (values
from 0 to 1).  This value will multiply the polarized terms by 1 + this
value.}

\item{n.before}{The number of words to consider as valence shifters before
the polarized word.}

\item{n.after}{The number of words to consider as valence shifters after
the polarized word.}

\item{question.weight}{The weighting of questions (values from 0 to 1).
Default is 1.  A 0 corresponds with the belief that questions (pure questions)
are not polarized.  A weight may be applied based on the evidence that the
questions function with polarized sentiment.}

\item{\ldots}{Ignored.}
}
\value{
Returns a \pkg{data.table} of:
\itemize{
  \item  element_id - The id number of the original vector passed to \code{sentiment}
  \item  sentence_id - The id number of the sentences within each \code{element_id}
  \item  word_count - Word count
  \item  sentiment - Sentiment/polarity score
}
}
\description{
Approximate the sentiment (polarity) of text by sentence.

Calulate text polarity sentiment at the sentence level and optionally
aggregate by rows or grouping variable(s).
}
\details{
The equation used by the algorithm to assign value to polarity of
each sentence fist utilizes the sentiment dictionary (Hu and Liu, 2004) to
tag polarized words.  A context cluster (\eqn{x_i^{T}}{x_i^T}) of words is
pulled from around this polarized word (default 4 words before and two words
after) to be considered as valence shifters.  The words in this context
cluster are tagged as neutral (\eqn{x_i^{0}}{x_i^0}), negator
(\eqn{x_i^{N}}{x_i^N}), amplifier (\eqn{x_i^{a}}{x_i^a}), or de-amplifier
(\eqn{x_i^{d}}{x_i^d}). Neutral words hold no value
in the equation but do affect word count (\eqn{n}).  Each polarized word is
then weighted \eqn{w} based on the weights from the \code{polarity.frame}
argument and then further weighted by the number and position of the valence
shifters directly surrounding the positive or negative word.  The researcher
may provide a weight \eqn{c} to be utilized with amplifiers/de-amplifiers
(default is .8; deamplifier weight is constrained to -1 lower bound).  Last,
these context cluster (\eqn{x_i^{T}}{x_i^T}) are summed and divided by the
square root of the word count (\eqn{\sqrt{n}}{\sqrtn}) yielding an unbounded
polarity score (\eqn{\delta}{C}).  Note that context clusters containing a
comma before the polarized word will only consider words found after the
comma.

\deqn{\delta=\frac{x_i^T}{\sqrt{n}}}{C=x_i^2/\sqrt(n)}

Where:

\deqn{x_i^T=\sum{((1 + c(x_i^{A} - x_i^{D}))\cdot w(-1)^{\sum{x_i^{N}}})}}{x_i^T=\sum((1 + c * (x_i^A - x_i^D)) * w(-1)^(\sumx_i^N))}

\deqn{x_i^{A}=\sum{(w_{neg}\cdot x_i^{a})}}{x_i^A=\sum(w_neg * x_i^a)}

\deqn{x_i^D = \max(x_i^{D'}, -1)}{x_i^D = max(x_i^D', -1)}

\deqn{x_i^{D'}= \sum{(- w_{neg}\cdot x_i^{a} + x_i^{d})}}{x_i^D'=\sum(- w_neg * x_i^a + x_i^d)}

\deqn{w_{neg}= \left(\sum{x_i^{N}}\right) \bmod {2}}{w_neg= (\sumx_i^N) mod 2}
}
\note{
The polarity score is dependent upon the polarity dictionary used.
This function defaults to the word polarity dictionary used by Hu, M., &
Liu, B. (2004), however, this may not be appropriate for the context of
children in a classroom.  The user may (is encouraged) to provide/augment the
dictionary (see the \code{sentiment_frame} function).  For instance the word
"sick" in a high school setting may mean that something is good, whereas
"sick" used by a typical adult indicates something is not right or negative
connotation (\strong{deixis}).
}
\examples{
mytext <- c(
   'do you like it?  But I hate really bad dogs',
   'I am the best friend.',
   'Do you really like it?  I\\'m not a fan'
)
sentiment(mytext)
sentiment(mytext, question.weight = 0)

sentiment(gsub("Sam-I-am", "Sam I am", sam_i_am))
}
\references{
Hu, M., & Liu, B. (2004). Mining opinion features in customer
reviews. National Conference on Artificial Intelligence.

\url{http://www.slideshare.net/jeffreybreen/r-by-example-mining-twitter-for}

\url{http://hedonometer.org/papers.html} Links to papers on hedonometrics
}
\seealso{
\url{https://github.com/trestletech/Sermon-Sentiment-Analysis}
}
\keyword{polarity}
\keyword{sentiment,}

