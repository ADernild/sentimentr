---
title: "sentimentr"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  md_document:
    toc: true      
---

```{r, echo=FALSE}
desc <- suppressWarnings(readLines("DESCRIPTION"))
regex <- "(^Version:\\s+)(\\d+\\.\\d+\\.\\d+)"
loc <- grep(regex, desc)
ver <- gsub(regex, "\\2", desc[loc])
verbadge <- sprintf('<a href="https://img.shields.io/badge/Version-%s-orange.svg"><img src="https://img.shields.io/badge/Version-%s-orange.svg" alt="Version"/></a></p>', ver, ver)
````

[![Project Status: Wip - Initial development is in progress, but there has not yet been a stable, usable release suitable for the public.](http://www.repostatus.org/badges/0.1.0/wip.svg)](http://www.repostatus.org/#wip)
[![Build Status](https://travis-ci.org/trinker/sentimentr.svg?branch=master)](https://travis-ci.org/trinker/sentimentr)
[![Coverage Status](https://coveralls.io/repos/trinker/sentimentr/badge.svg?branch=master)](https://coveralls.io/r/trinker/sentimentr?branch=master)
`r verbadge`

<img src="inst/sentimentr_logo/r_sentimentr.png" width="150" alt="readability Logo">  

**sentimentr** is designed to quickly calulate text polarity sentiment at the sentence level and optionally aggregate by rows or grouping variable(s).

The equation used by the algorithm to assign value to polarity of each sentence fist utilizes the sentiment dictionary (Hu and Liu, 2004) to tag polarized words.  Each paragraph ($p_i = \{s_1, s_2, ..., s_n\}$) composed of sentences, is broken into element sentences ($s_ij = \{w_1, w_2, ..., w_n\}$) where $w$ are the words within sentences.  Each sentence ($s_j$) is broken into a an ordered bag of words.  Punctuation is removed with the exception of pause punctuations (commas, colons, semicolons) which are considered a word within the sentence.  I will denote pause words as $cw$ (comma words) for
convience.  We can represent these words as an ijk notation as $w_{ijk}$.  For example $w_{325}$ would be the fifth word of the second sentence of the third paragraph.  While I use the term paragraph this merely represent a complete turn of talk.  For example t may be a cell level response in a questionare comprosed of sentences.

The words in each sentence ($w_{ijk}$) are searched and compared to a modified version of Hu, M., & Liu, B.'s (2004) dictionary of polarized words. Positive ($w_{ijk}^{+}$) and negative ($w_{ijk}^{-}$) words are tagged with a $+1$ and $-1$
respectively (or other positive/negative weighting if the user provides the sentiment dictionary).  I will denote polarized words as $pw$ for convience. These will form a polar cluster ($c_{ijl}$) which is a subset of the a sentence ($c_{ijl} \subseteq s_ij$).

The polarized context cluster ($c_{ijl}$) of words is pulled from around the polarized word ($pw}) and defaults to 4 words before and two words after $pw$) to be considered as valence shifters.  The cluster can be represented as ($c_{ijl} = \{pw_{ijk - nb}, ..., pw_{ijk} , ..., pw_{ijk - na}\}$), where $nb$ & $na$ are the parameters `n.before` and `n.after` set by the user.  The words in this polarized context cluster are tagged as neutral ($w_{ijk}^{0}$), negator ($w_{ijk}^{n}$),
amplifier ($w_{ijk}^{a}$), or de-amplifier ($w_{ijk}^{d}$). Neutral words hold no value in the equation but do affect word count ($n$).  Each polarized word is then weighted ($w$) based on the weights from the `polarity_dt` argument and then further weighted by the function and number of the valence shifters directly surrounding the positive or negative word ($pw$).  Pause ($cw$) locations (punctuation that denotes a pause including commas, colons, and semicolons) are indexed and considered in calculating the upper and lower bounds in the polarized context cluster. This is because these marks indicate a change in thought and words prior are not necessarily connected with words after these punctuation marks.  The lower bound of the polarized context cluster is constrained to $\max \{pw_{ijk - nb}, 1, \max \{cw_{ijk} < pw_{ijk}\}\}$ and the upper bound is constrained to $\min \{pw_{ijk + na}, w_{ijn}, \min \{cw_{ijk} > pw_{ijk}\}\}$ where $w_{ijn}$ is the number of words in the sentence.

The core value in the cluster, the polarized word is acted uppon by valence shifters. Amplifiers increas the polarity by 1.8 (.8 is the default weight ($z$)).  Amplifiers ($w_{ijk}^{a}$) become de-amplifiers if the clontext cluster contains an odd number of negators ($w_{ijk}^{n}$).  De-amplifiers work to decrease decrease the polarity.  Negation ($w_{ijk}^{n}$) acts on amplifiers/de-amplifiers as discussed but also flip the sign of the polarized word.  Negation is determined by raising $-1$ to the power of the number of negators ($w_{ijk}^{n}$).  Simply, this is a result of a belief that two
negatives qual a positive, 3 negatives a negative and so on.

The researcher may provide a weight ($z$) to be utilized with amplifiers/de-amplifiers (default is $.8$; de-amplifier weight is constrained to $-1$ lower bound).  Last, these weighted context clusters ($c_{ijl}$) are summed ($c'_{ij}$) and divided by the square root of the word count (&radic$w_{ijn}$) yielding an unbounded polarity score ($\delta_{ij}$) for each sentence.


$$\delta_{ij}=c'_{ij}/&radic{w_{ijn}$$

Where:

$$c'_{ij}=\sum{((1 + w_{amp} + w_{deamp})\cdot w_{ijk}^{p}(-1)^{\sum{w_{ijk}^{n}}})}$$

$$w_{amp}=\sum{(w_{neg}\cdot (z \cdot w_{ijk}^{a}))}$$

$$w_{deamp} = \max(w_{deamp'}, -1)$$

$$w_{deamp'}= \sum{(z(- w_{neg}\cdot w_{ijk}^{a} + w_{ijk}^{d}))}$$

$$w_{neg}= \left(\sum{w_{ijk}^{n}}\right) \bmod {2}$$


# Installation

To download the development version of **sentimentr**:

Download the [zip ball](https://github.com/trinker/sentimentr/zipball/master) or [tar ball](https://github.com/trinker/sentimentr/tarball/master), decompress and run `R CMD INSTALL` on it, or use the **pacman** package to install the development version:

```r
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("trinker/sentimentr")
```

# Contact

You are welcome to:
* submit suggestions and bug-reports at: <https://github.com/trinker/sentimentr/issues>
* send a pull request on: <https://github.com/trinker/sentimentr/>
* compose a friendly e-mail to: <tyler.rinker@gmail.com>

# Examples

```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(sentimentr)
```

```{r}
mytext <- c(
    'do you like it?  But I hate really bad dogs',
    'I am the best friend.',
    'Do you really like it?  I\'m not a fan'
)
sentiment(mytext)
```
